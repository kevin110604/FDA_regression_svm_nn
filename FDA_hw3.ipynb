{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA_hw3\n",
    "\n",
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2009</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2009</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2009</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
       "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
       "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
       "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
       "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
       "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Close Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2018</td>\n",
       "      <td>2683.73</td>\n",
       "      <td>2695.81</td>\n",
       "      <td>2695.89</td>\n",
       "      <td>2682.36</td>\n",
       "      <td>1846463232</td>\n",
       "      <td>2713.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-Jan-2018</td>\n",
       "      <td>2697.85</td>\n",
       "      <td>2713.06</td>\n",
       "      <td>2714.37</td>\n",
       "      <td>2697.77</td>\n",
       "      <td>2090595328</td>\n",
       "      <td>2723.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-Jan-2018</td>\n",
       "      <td>2719.31</td>\n",
       "      <td>2723.99</td>\n",
       "      <td>2729.29</td>\n",
       "      <td>2719.07</td>\n",
       "      <td>2100767744</td>\n",
       "      <td>2743.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-Jan-2018</td>\n",
       "      <td>2731.33</td>\n",
       "      <td>2743.15</td>\n",
       "      <td>2743.45</td>\n",
       "      <td>2727.92</td>\n",
       "      <td>1918869120</td>\n",
       "      <td>2747.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2018</td>\n",
       "      <td>2742.67</td>\n",
       "      <td>2747.71</td>\n",
       "      <td>2748.51</td>\n",
       "      <td>2737.60</td>\n",
       "      <td>1894823936</td>\n",
       "      <td>2751.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232   \n",
       "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328   \n",
       "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744   \n",
       "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120   \n",
       "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936   \n",
       "\n",
       "   Tomorrow Close Price  \n",
       "0               2713.06  \n",
       "1               2723.99  \n",
       "2               2743.15  \n",
       "3               2747.71  \n",
       "4               2751.29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Tomorrow Close Price'] = train['Close Price'].shift(-1)\n",
    "test['Tomorrow Close Price'] = test['Close Price'].shift(-1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Close Price</th>\n",
       "      <th>Tomorrow Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2009</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "      <td>927.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>934.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>906.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2009</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>909.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2009</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>890.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-2009</td>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "      <td>870.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12-Jan-2009</td>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "      <td>871.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13-Jan-2009</td>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "      <td>842.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14-Jan-2009</td>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "      <td>843.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-Jan-2009</td>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "      <td>850.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080   \n",
       "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016   \n",
       "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032   \n",
       "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032   \n",
       "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952   \n",
       "5  09-Jan-2009      909.91       890.35      911.93     888.31  4716499968   \n",
       "6  12-Jan-2009      890.40       870.26      890.40     864.32  4725049856   \n",
       "7  13-Jan-2009      869.79       871.79      877.02     862.02  5017469952   \n",
       "8  14-Jan-2009      867.28       842.62      867.28     836.93  5407880192   \n",
       "9  15-Jan-2009      841.99       843.74      851.59     817.04  7807350272   \n",
       "\n",
       "   Tomorrow Close Price  Tomorrow Increase  \n",
       "0                927.45                  0  \n",
       "1                934.70                  1  \n",
       "2                906.65                  0  \n",
       "3                909.73                  1  \n",
       "4                890.35                  0  \n",
       "5                870.26                  0  \n",
       "6                871.79                  1  \n",
       "7                842.62                  0  \n",
       "8                843.74                  1  \n",
       "9                850.12                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x[1] > x[0]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['Tomorrow Increase'] = train[['Close Price', 'Tomorrow Close Price']].apply(f, axis=1)\n",
    "test['Tomorrow Increase'] = test[['Close Price', 'Tomorrow Close Price']].apply(f, axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0      902.99       931.80      934.73     899.35  4048270080   \n",
       "1      929.17       927.45      936.63     919.53  5413910016   \n",
       "2      931.17       934.70      943.85     927.28  5392620032   \n",
       "3      927.45       906.65      927.45     902.37  4704940032   \n",
       "4      905.73       909.73      910.00     896.81  4991549952   \n",
       "\n",
       "   Tomorrow Increase  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['Date', 'Tomorrow Close Price'], axis=1)\n",
    "test = test.drop(['Date', 'Tomorrow Close Price'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price      Volume\n",
       "0      902.99       931.80      934.73     899.35  4048270080\n",
       "1      929.17       927.45      936.63     919.53  5413910016\n",
       "2      931.17       934.70      943.85     927.28  5392620032\n",
       "3      927.45       906.65      927.45     902.37  4704940032\n",
       "4      905.73       909.73      910.00     896.81  4991549952\n",
       "5      909.91       890.35      911.93     888.31  4716499968\n",
       "6      890.40       870.26      890.40     864.32  4725049856\n",
       "7      869.79       871.79      877.02     862.02  5017469952\n",
       "8      867.28       842.62      867.28     836.93  5407880192\n",
       "9      841.99       843.74      851.59     817.04  7807350272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Tomorrow Increase'\n",
    "x_train = train.loc[:, train.columns != col]\n",
    "y_train = train[col]\n",
    "x_test = test.loc[:, test.columns != col]\n",
    "y_test = test[col]\n",
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.551957</td>\n",
       "      <td>-1.494082</td>\n",
       "      <td>-1.505124</td>\n",
       "      <td>-1.540593</td>\n",
       "      <td>0.813446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.498010</td>\n",
       "      <td>-1.503047</td>\n",
       "      <td>-1.501205</td>\n",
       "      <td>-1.499034</td>\n",
       "      <td>1.823778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.493889</td>\n",
       "      <td>-1.488105</td>\n",
       "      <td>-1.486312</td>\n",
       "      <td>-1.483074</td>\n",
       "      <td>1.808027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.501555</td>\n",
       "      <td>-1.545913</td>\n",
       "      <td>-1.520140</td>\n",
       "      <td>-1.534374</td>\n",
       "      <td>1.299265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.546311</td>\n",
       "      <td>-1.539566</td>\n",
       "      <td>-1.556133</td>\n",
       "      <td>-1.545824</td>\n",
       "      <td>1.511306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price    Volume\n",
       "0   -1.551957    -1.494082   -1.505124  -1.540593  0.813446\n",
       "1   -1.498010    -1.503047   -1.501205  -1.499034  1.823778\n",
       "2   -1.493889    -1.488105   -1.486312  -1.483074  1.808027\n",
       "3   -1.501555    -1.545913   -1.520140  -1.534374  1.299265\n",
       "4   -1.546311    -1.539566   -1.556133  -1.545824  1.511306"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_std = x_train\n",
    "x_train_std = (x_train_std - x_train_std.mean()) / x_train_std.std()\n",
    "x_test_std = x_test\n",
    "x_test_std = (x_test_std - x_test_std.mean()) / x_test_std.std()\n",
    "x_train_std.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    train_preds = model.predict(x_train)\n",
    "    test_preds = model.predict(x_test)\n",
    "    train_acc = metrics.accuracy_score(y_train, train_preds)\n",
    "    test_acc = metrics.accuracy_score(y_test, test_preds)\n",
    "    print('Train accuracy: %s' % train_acc)\n",
    "    print('Test accuracy: %s' % test_acc)\n",
    "    print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5163427561837456\n",
      "Test accuracy: 0.5674603174603174\n",
      "[1 1 1 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "model_bl = linear_model.SGDClassifier(loss='log', max_iter=10000, tol=1e-3,\n",
    "                                      learning_rate='adaptive', eta0=0.87)\n",
    "model_bl.fit(x_train, y_train)\n",
    "evaluate(model_bl, x_train_std, y_train, x_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4916077738515901\n",
      "Test accuracy: 0.4444444444444444\n",
      "[0 0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 0 0\n",
      " 0 1 1 1 1 1 0 0 0 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 1 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 0\n",
      " 0 1 0 1 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1\n",
      " 1 1 1 0 0 0 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "evaluate(clf, x_train_std, y_train, x_test_std, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.11792884,  2.14183026,  2.1280369 ,  2.13182543, -0.81568088],\n",
       "       [ 2.14703114,  2.17738855,  2.16616345,  2.16356794, -0.6350265 ],\n",
       "       [ 2.19126169,  2.1999191 ,  2.19694528,  2.20744305, -0.62749905],\n",
       "       ...,\n",
       "       [ 1.62073705,  1.71517201,  1.7014033 ,  1.54595882, -0.41608606],\n",
       "       [ 1.73671343,  1.70880244,  1.76571091,  1.70034565, -0.64232918],\n",
       "       [ 1.73706381,  1.75231754,  1.74295464,  1.7208001 , -0.76668134]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_std = scaler.transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)\n",
    "x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Custom kernel function\\ndef my_kernel(X, Y):\\n    return np.dot(X, Y.T)\\n  \\npenalty = 0.05\\n\\nsvm = SVC(C=penalty, kernel=\"linear\", probability=True)\\nsvm.fit(x_train, y_train)\\n  \\nacc_rate = accuracy_score(y_test, svm.predict(x_test)) * 100\\nprint(\"Penalty = %.2f, Accuracy = %.2f %%\" % (penalty, acc_rate))\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "'''\n",
    "# Custom kernel function\n",
    "def my_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)\n",
    "  \n",
    "penalty = 0.05\n",
    "\n",
    "svm = SVC(C=penalty, kernel=\"linear\", probability=True)\n",
    "svm.fit(x_train, y_train)\n",
    "  \n",
    "acc_rate = accuracy_score(y_test, svm.predict(x_test)) * 100\n",
    "print(\"Penalty = %.2f, Accuracy = %.2f %%\" % (penalty, acc_rate))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers, regularizers\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1236\n",
       "0    1028\n",
       "Name: Tomorrow Increase, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    131\n",
       "0    121\n",
       "Name: Tomorrow Increase, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = 5\n",
    "hidden_units = 10    # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.1  # how big our steps are in gradient descent\n",
    "epochs = 20          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=input_dimension,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "# define our loss function and optimizer\n",
    "# Adam is a kind of gradient descent\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "2264/2264 [==============================] - 0s 147us/step - loss: 0.7079 - acc: 0.5177\n",
      "Epoch 2/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 0.6907 - acc: 0.5239\n",
      "Epoch 3/10\n",
      "2264/2264 [==============================] - 0s 49us/step - loss: 0.6905 - acc: 0.5362\n",
      "Epoch 4/10\n",
      "2264/2264 [==============================] - 0s 49us/step - loss: 0.6914 - acc: 0.5424\n",
      "Epoch 5/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 0.6921 - acc: 0.5345\n",
      "Epoch 6/10\n",
      "2264/2264 [==============================] - 0s 55us/step - loss: 0.6901 - acc: 0.5459\n",
      "Epoch 7/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 0.6911 - acc: 0.5459\n",
      "Epoch 8/10\n",
      "2264/2264 [==============================] - 0s 53us/step - loss: 0.6912 - acc: 0.5309\n",
      "Epoch 9/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 0.6916 - acc: 0.5380\n",
      "Epoch 10/10\n",
      "2264/2264 [==============================] - 0s 49us/step - loss: 0.6906 - acc: 0.5389\n",
      "2264/2264 [==============================] - 0s 34us/step\n",
      "252/252 [==============================] - 0s 30us/step\n",
      "Training accuracy: 0.5459363958650258\n",
      "Testing accuracy: 0.5238095242825765\n"
     ]
    }
   ],
   "source": [
    "# train the parameters\n",
    "history = model.fit(x_train_std, y_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(x_train_std, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(x_test_std, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.496383  ],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296],\n",
       "       [0.50003296]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3X2UlOV9//H3R558FsQ1KqBgXDTobIiuJCYxEhXEaMUao9jamrTR0ybGaNsk2uRXzyH1RHPSapOYWKLmZ/tLhBSN3SRapRqj8SGy+AgogvgARCMBFEEEFr6/P657ZFiX3Vl2du+dmc/rnDk7c819z1z3ws5nrof7vhQRmJmZ7cgueVfAzMz6NweFmZl1ykFhZmadclCYmVmnHBRmZtYpB4WZmXXKQWFmZp1yUJiZWaccFGZm1qmBeVegEvbbb78YPXp03tUwM6sq8+bN+2NENHS1XU0ExejRo2ltbc27GmZmVUXSy+Vs564nMzPrlIPCzMw65aAwM7NOOSjMzKxTDgozM+uUg8LMzDrloDAzs07Vd1DMnw9f+xqsXZt3TczM+q36DooXX4RvfzsFhpmZdaisoJA0RdIiSUskXd7B89dKejK7PS/pjZLnLpC0OLtdkJXtVbL9k5L+KOm67LnPSlpZ8tznK3Ww79HUlH4+80yvvYWZWbXr8hIekgYA1wOTgOXAXEktEbGwuE1EXFay/ZeAD2X39wWuBJqBAOZl+64BxpfsMw+4veRtZ0XExT05sLIcfDDsvbeDwsysE+W0KCYASyJiaURsAmYCUzvZ/jzg1uz+KcCciFidhcMcYErpxpLGAvsDD3a38j0mwVFHwdNP9/lbm5lVi3KCYgSwrOTx8qzsPSQdAowB7uvGvtNILYgoKfu0pKclzZY0qow67rxCIbUotnt7MzMrqvRg9jRgdkRs6eY+t5Y8/gUwOiKaSC2QWzraSdJFklolta5cuXKnK0xTE7zxBqxYsfOvYWZWw8oJihVA6bf6kVlZR9p/6He6r6QPAgMjYl6xLCJWRcTG7OGNwDEdvVFEzIiI5ohobmjo8nLqO1YopJ/ufjIz61A5QTEXaJQ0RtJgUhi0tN9I0hHAMOCRkuK7gcmShkkaBkzOyopKxzOKr3NgycMzgGfLOZCddtRR6acHtM3MOtTlrKeIaJN0MekDfgBwc0QskDQdaI2IYmhMA2aWjjVExGpJ3ySFDcD0iFhd8vLnAJ9q95aXSDoDaANWA5/dieMq37BhMGqUg8LMbAcUNTCI29zcHD1a4e6002DZMnc/mVldkTQvIpq72q6+z8wuKhTguedg8+a8a2Jm1u84KCDNfNq8GRYtyrsmZmb9joMCts188jiFmdl7OCgADj8cBg70GIWZWQccFACDB8MRR7hFYWbWAQdFUVOTg8LMrAMOiqJCAV55JV3Ow8zM3uWgKCoOaHsRIzOz7TgoiryIkZlZhxwURSNHwj77eOaTmVk7DooiadvaFGZm9i4HRanizKcauP6VmVmlOChKFQqwdm2a/WRmZoCDYnu+lIeZ2Xs4KEp5ESMzs/dwUJTaZx845BAHhZlZCQdFe4WCp8iamZVwULRXKKR1KTZtyrsmZmb9goOivaYmaGtLK96ZmVl5QSFpiqRFkpZIuryD56+V9GR2e17SGyXPXSBpcXa7oKT8/uw1i/vtn5UPkTQre6/fSRrd88PshuLMJ3c/mZkBMLCrDSQNAK4HJgHLgbmSWiJiYXGbiLisZPsvAR/K7u8LXAk0AwHMy/Zdk23+5xHR2u4t/xpYExGHSZoGXAOcu7MH2G1jx8KgQR7QNjPLlNOimAAsiYilEbEJmAlM7WT784Bbs/unAHMiYnUWDnOAKV2831Tgluz+bOAkSSqjnpUxaBCMG+egMDPLlBMUI4BlJY+XZ2XvIekQYAxwX5n7/jjrdvo/JWHw7j4R0Qa8CQzv4L0uktQqqXXlypVlHEY3eOaTmdm7Kj2YPQ2YHRFbytj2zyOiAByf3f6iO28UETMiojkimhsaGnaiqp0oFGDFClizputtzcxqXDlBsQIYVfJ4ZFbWkWls63bqdN+IKP58C/gpqYtru30kDQT2AVaVUc/K8aU8zMzeVU5QzAUaJY2RNJgUBi3tN5J0BDAMeKSk+G5gsqRhkoYBk4G7JQ2UtF+23yDgdKC4tFwLUJwddTZwX0QfX87VixiZmb2ry1lPEdEm6WLSh/4A4OaIWCBpOtAaEcXQmAbMLP1Qj4jVkr5JChuA6VnZHqTAGJS95v8CP8q2uQn4T0lLgNXZ6/atgw6CYcM8TmFmBqivv6z3hubm5mhtbT/LtodOOAE2b4aHH67s65qZ9ROS5kVEc1fb+czsHWlqgvnzYevWvGtiZpYrB8WOFArw1lvw8st518TMLFcOih3xzCczM8BBsWNexMjMDHBQ7Nhee8GYMZ75ZGZ1z0HRmULBLQozq3sOis4UCvD88/DOO3nXxMwsNw6KzjQ1wZYt8OyzedfEzCw3DorOeOaTmZmDolONjTBkiIPCzOqag6IzAwd6ESMzq3sOiq54ESMzq3MOiq4UCvDqq7Cqb5fEMDPrLxwUXfHaFGZW5xwUXSnOfHL3k5nVKQdFVw44AIYPd4vCzOqWg6Irki/lYWZ1zUFRDi9iZGZ1zEFRjkIB1q+HF1/MuyZmZn2urKCQNEXSIklLJF3ewfPXSnoyuz0v6Y2S5y6QtDi7XZCV7S7pV5Kek7RA0tUl239W0sqS1/t8JQ60R3wpDzOrYwO72kDSAOB6YBKwHJgrqSUiFha3iYjLSrb/EvCh7P6+wJVAMxDAPEktwEbgOxHxa0mDgXslnRoRd2UvMysiLq7IEVbCkUemsYpnnoEzz8y7NmZmfaqcFsUEYElELI2ITcBMYGon258H3JrdPwWYExGrI2INMAeYEhFvR8SvAbLXfBwYubMH0ev23BMOPdRTZM2sLpUTFCOAZSWPl2dl7yHpEGAMcF+5+0oaCvwJcG9J8aclPS1ptqRRO3iviyS1SmpduXJlGYfRQ575ZGZ1qtKD2dOA2RGxpZyNJQ0ktT6+GxFLs+JfAKMjoonUArmlo30jYkZENEdEc0NDQwWq3oWmJli8GDZs6P33MjPrR8oJihVA6bf6kVlZR6axrdupnH1nAIsj4rpiQUSsioiN2cMbgWPKqGPvKxTS9NiFC7ve1syshpQTFHOBRkljsoHnaUBL+40kHQEMAx4pKb4bmCxpmKRhwOSsDEn/DOwDXNrudQ4seXgG0D+Wl/PMJzOrU13OeoqINkkXkz7gBwA3R8QCSdOB1ogohsY0YGZERMm+qyV9kxQ2ANOzspHA14HngMclAXw/Im4ELpF0BtAGrAY+W4kD7bHDDoNdd3VQmFndUcnnetVqbm6O1tbWvngjGDYM5szp/fcyM+tlkuZFRHNX2/nM7O7wzCczq0MOiu4oFOAPf4DXX8+7JmZmfcZB0R1exMjM6pCDojs888nM6pCDojve9z5oaHBQmFldcVB0V1OTg8LM6oqDorsKhbSI0ZayrlJiZlb1HBTdVSik6z0tXdr1tmZmNcBB0V0e0DazOuOg6K7iIkZem8LM6oSDort23z1d98ktCjOrEw6KneFLeZhZHXFQ7IymJliyBNavz7smZma9zkGxMwoFiPAiRmZWFxwUO8Mzn8ysjjgodsahh6ZBbQeFmdUBB8XOGDAgTZP1FFkzqwMOip3lmU9mVifKCgpJUyQtkrRE0uUdPH+tpCez2/OS3ih57gJJi7PbBSXlx0h6JnvN7ypbOFvSvpLmZNvPkTSsEgdacYUCrFyZFjIyM6thXQaFpAHA9cCpwDjgPEnjSreJiMsiYnxEjAe+B9ye7bsvcCXwYWACcGXJB/8PgQuBxuw2JSu/HLg3IhqBe7PH/U9xESN3P5lZjSunRTEBWBIRSyNiEzATmNrJ9ucBt2b3TwHmRMTqiFgDzAGmSDoQ2DsiHo2IAP4DODPbZypwS3b/lpLy/sUzn8ysTpQTFCOAZSWPl2dl7yHpEGAMcF8X+47I7nf0mu+LiFez+68B7yujjn2voSEtZOSgMLMaV+nB7GnA7IioyGINWWsjOnpO0kWSWiW1rly5shJv131NTe56MrOaV05QrABGlTwemZV1ZBrbup0623dFdr+j1/xD1jVF9vP1jt4oImZERHNENDc0NJRxGL2gUEhnZ3sRIzOrYeUExVygUdIYSYNJYdDSfiNJRwDDgEdKiu8GJksalg1iTwbuzrqW1kr6SDbb6S+B/872aQGKs6MuKCnvfwoFeOeddN0nM7Ma1WVQREQbcDHpQ/9Z4GcRsUDSdElnlGw6DZiZdRcV910NfJMUNnOB6VkZwBeAG4ElwAvAXVn51cAkSYuBk7PH/ZNnPplZHVDJ53rVam5ujtbW1r5/4w0bYM894etfh+nT+/79zcx6QNK8iGjuajufmd0Tu+0GjY2e+WRmNc1B0VO+lIeZ1TgHRU81NcELL8C6dXnXxMysVzgoeqp4hvaCBfnWw8yslzgoesqX8jCzGueg6KkxY2CPPTxF1sxqloOip3bZBY46yi0KM6tZDopKKM58qoFzUszM2nNQVEJTE6xaBa++2vW2ZmZVxkFRCR7QNrMa5qCoBAeFmdUwB0UlDB8OBx7omU9mVpMcFJXS1OQWhZnVJAdFpRQK8Oyz0NaWd03MzCrKQVEphQJs3AiLF+ddEzOzinJQVIoXMTKzGuWgqJQPfAAGDPA4hZnVHAdFpQwZAmPHOijMrOY4KCqpqcldT2ZWc8oKCklTJC2StETS5TvY5hxJCyUtkPTTkvJrJM3PbueWlD8o6cns9ntJd2TlEyW9WfLcP/X0IPtMoQAvvQRvvZV3TczMKmZgVxtIGgBcD0wClgNzJbVExMKSbRqBK4CPRcQaSftn5acBRwPjgSHA/ZLuioi1EXF8yf63Af9d8rYPRsTpPT+8PlY8Q3v+fDjuuHzrYmZWIeW0KCYASyJiaURsAmYCU9ttcyFwfUSsAYiI17PyccADEdEWEeuBp4EppTtK2hs4Ebhj5w+jnygGhbufzKyGlBMUI4BlJY+XZ2WlxgJjJT0k6VFJxTB4CpgiaXdJ+wGfBEa12/dM4N6IWFtSdpykpyTdJenIso8mb4ccAnvt5QFtM6spXXY9deN1GoGJwEjgAUmFiLhH0rHAw8BK4BFgS7t9zwNuLHn8OHBIRKyT9ClSS6Ox/RtKugi4CODggw+u0GH0kBcxMrMaVE6LYgXbtwJGZmWllgMtEbE5Il4Enif7cI+IqyJifERMApQ9B0DWypgA/KpYlo1frMvu3wkMyrbbTkTMiIjmiGhuaGgo4zD6iBcxMrMaU05QzAUaJY2RNBiYBrS02+YOUmui+OE/FlgqaYCk4Vl5E9AE3FOy39nALyPinWKBpAMkKbs/Iavjqp04tnw0NcGaNbCifZaamVWnLrueIqJN0sXA3cAA4OaIWCBpOtAaES3Zc5MlLSR1LX0lIlZJ2hV4MPvcXwucHxGlV82bBlzd7i3PBv5WUhuwAZgWUUVfz0vXphg5Mt+6mJlVgKrpM3hHmpubo7W1Ne9qJGvWwL77wjXXwFe/mndtzMx2SNK8iGjuajufmV1pw4alloSnyJpZjXBQ9IbigLaZWQ1wUPSG4iJGmzfnXRMzsx5zUPSGQiGFxKJFedfEzKzHHBS9obiIkbufzKwGOCh6wxFHwMCBDgozqwkOit4weDAcfrhnPplZTXBQ9JamJrcozKwmOCh6S6EAr7wCb76Zd03MzHrEQdFbShcxMjOrYg6K3lKc+eRxCjOrcg6K3jJqFOyzj8cpzKzqOSh6i+RFjMysJjgoepMXMTKzGuCg6E1NTWnW07JlXW9rZtZPOSh6U+kiRmZmVcpB0ZuOOir99MwnM6tiDoreNHQoHHywWxRmVtUcFL3NixiZWZUrKygkTZG0SNISSZfvYJtzJC2UtEDST0vKr5E0P7udW1L+fyW9KOnJ7DY+K5ek72bv9bSko3t6kLkqFOC552DTprxrYma2UwZ2tYGkAcD1wCRgOTBXUktELCzZphG4AvhYRKyRtH9WfhpwNDAeGALcL+muiFib7fqViJjd7i1PBRqz24eBH2Y/q1NTE7S1pbAonq1tZlZFymlRTACWRMTSiNgEzASmttvmQuD6iFgDEBGvZ+XjgAcioi0i1gNPA1O6eL+pwH9E8igwVNKBZR5P/+OZT2ZW5coJihFA6YkAy7OyUmOBsZIekvSopGIYPAVMkbS7pP2ATwKjSva7KuteulbSkG68H5IuktQqqXXlypVlHEZODj8cBg1yUJhZ1arUYPZAUlfRROA84EeShkbEPcCdwMPArcAjwJZsnyuAI4BjgX2Br3XnDSNiRkQ0R0RzQ0NDRQ6iVwwalFa88xRZM6tS5QTFCrZvBYzMykotB1oiYnNEvAg8TwoOIuKqiBgfEZMAZc8REa9m3UsbgR+TurjKfb/q4kWMzKyKlRMUc4FGSWMkDQamAS3ttrmD1Jog62IaCyyVNEDS8Ky8CWgC7skeH5j9FHAmUFy4oQX4y2z200eANyPi1Z0/xH6gUIDly2HNmrxrYmbWbV3OeoqINkkXA3cDA4CbI2KBpOlAa0S0ZM9NlrSQ1LX0lYhYJWlX4MGUBawFzo+ItuylfyKpgdTKeBL4m6z8TuBTwBLgbeBzFTrW/JQOaH/iE/nWxcysmxQ1cGXT5ubmaG1tzbsaO7Z8eVqf4vvfhy9+Me/amJkBIGleRDR3tZ3PzO4LI0aky3l4nMLMqpCDoi9IqfvJM5/MrAo5KPpKUxPMn+9FjMys6jgo+kqhAG+9BS+/nHdNzMy6xUHRV3wpDzOrUg6KvuJFjMysSjko+sree8Po0W5RmFnVcVD0JS9iZGZVyEHRlwoFWLQINm7MuyZmZmVzUPSlpibYsgWefTbvmpiZlc1B0Zc888nMqpCDoi81NsLgwZ75ZGZVxUHRlwYNgnHj3KIws6rioOhrnvlkZlXGQdHXCgX4/e9h1aq8a2JmVhYHRV/zgLaZVRkHRV9rako/HRRmViUcFH3twANh330dFGZWNcoKCklTJC2StETS5TvY5hxJCyUtkPTTkvJrJM3PbueWlP8ke835km6WNCgrnyjpTUlPZrd/6ulB9itexMjMqkyXQSFpAHA9cCowDjhP0rh22zQCVwAfi4gjgUuz8tOAo4HxwIeBf5C0d7bbT4AjgAKwG/D5kpd8MCLGZ7fpPTi+/qm4iNHWrXnXxMysS+W0KCYASyJiaURsAmYCU9ttcyFwfUSsAYiI17PyccADEdEWEeuBp4Ep2TZ3RgZ4DBjZ88OpEoUCrF8PL72Ud03MzLpUTlCMAJaVPF6elZUaC4yV9JCkRyVNycqfAqZI2l3SfsAngVGlO2ZdTn8B/E9J8XGSnpJ0l6Qju3E81aE488ndT2ZWBQZW8HUagYmklsEDkgoRcY+kY4GHgZXAI8CWdvv+gNTqeDB7/DhwSESsk/Qp4I7stbcj6SLgIoCDDz64QofRR4qLGD3zDJx5Zr51MTPrQjktihVs3woYmZWVWg60RMTmiHgReJ7swz0irsrGGiYByp4DQNKVQAPwd8WyiFgbEeuy+3cCg7LWyHYiYkZENEdEc0NDQxmH0Y/suScceqhnPplZVSgnKOYCjZLGSBoMTANa2m1zB6k1QfahPhZYKmmApOFZeRPQBNyTPf48cApwXkS8O6or6QBJyu5PyOpYe6cxe+aTmVWJLrueIqJN0sXA3cAA4OaIWCBpOtAaES3Zc5MlLSR1LX0lIlZJ2hV4MPvcXwucHxFt2UvfALwMPJI9f3s2w+ls4G8ltQEbgGnZgHdtKRTgF7+ADRtgt93yro2V2rwZWlvh8cfhlFPgsMPyrpFZrlQLn8HNzc3R2tqadzW657/+C845B+bNg6OPzrs29W3TJpg7F+6/H37zG3j44TQrDVKIf+tb8KUvwS4+P9Vqi6R5EdHc1Xb+n58XX/MpPxs3wgMPwDe/CSedBEOHwsc/Dt/4Brz2GnzuczB7dvq3OfFEuPRS+OQn4YUX8q65WS4qNevJuuuww2DIEI9T9IUNG+DRR1Nr4Te/gUceSWEhwQc/CBddBCecAJ/4BAwfvv2+v/gF3HJLCoumJrj6avjiF926sLrioMjLwIFw5JFuUfSGt99OYVDsSvrd71L30i67wPjx6YP+hBPg+ONh2LDOX0uCz34WTj4ZLrwQLrkEbrsNbr45zVwzqwMOijwVCnD33XnXovqtW5fGFYothsceSwPSAwak8Z9LLoGJE1P30j777Nx7jBwJd94JP/4xXHZZal18+9vwN3/j1kU9Ko7tpok4Nc9BkadCIXVrrFwJ1XYuSJ7eegt++9ttwdDaCm1tKRiOPRb+7u9Si+FjH4O99+769colwV/9FUyaBJ//fGqZ3HYb3HQTjB5dufex/mHrVlixAhYvhiVLtv1csiSNV+23H3z60+n20Y/W9BcGz3rK05w5MHky3HtvGjS1jr355rZguP/+NG11y5a0Bvmxx6bWwgknpD/WPffsmzpFwI03wt//fbr/ne+ksY46+YZZM7ZuhWXLtgVAaSi88EIayyoaPBje/35obEw/X3gh9Qhs3JiWDzjrrBQaxx+fuparQLmznhwUeXrttfQf7Lrr4Mtfzrs2/ccbb6RZScUWwxNPpD/owYPhwx9OoTBxIhx3HOy+e751feUV+Ou/hv/93zSOceONcMgh+dbJtrdly7YwaN86WLp0+zAYMiRNNCneGhu33R85MrVaS61dC7/6VWpZ3nlnmjjR0JAuzXP22Wm23KBBfXu83eCgqAYRsP/+cMYZqfuiXm3enGYlzZkD99yTzmnYujX90R53XAqGE06Aj3ykf56cGAEzZsA//ENqUfzLv6SuKbcu+s6WLSm0S7uHSsNg06Zt2+66a8dB0NgII0bsfBfS+vVw110pNH75yzR2NmwYTJ2aQuPkk9P/6X7EQVEtTjwx/Yd67LG8a9J3ImDRohQMc+bAr3+dfge77JJaDJMmpfMbJkxIf9TV4qWXUuvivvvSGd0/+hGMGtXlblZi69b0ob5xY/pZeiuWrVr13jGDpUvTF46i3XbrOAgOOwwOOqj3xxPeeSd96Zk9G1paUvfp3nvDn/xJCo1TTukXX3ocFNXi0kvTB8pbb9X0YBh//GPqnimGw7LsyvXvf38ap5k0KTXThw7Nt549tXUr3HADfPWrqZvi2mvTCXzV3rp47rk0TvTOOx1/kFfq8Zb2F5fuxB577Lib6KCD+s/vfOPGNA55221wxx2wenWq+2mnpdA49dS+G1trx0FRLW66KXVTLF5cW9cU2rgRHnpoW3fSE0+klsTQoam1UAyHMWPyrmnvWLo0zZD6zW/SB8GMGamPu5osXQqzZqXbU091vM3AgWnsqHgbMqR7j3dmn6FD09/KAQf0nzAo1+bN6f/E7Nnw85/D66+nVvOpp6bQOP30ys7U64KDolo89ljqbrnttjRrolpFwIIFKRTmzEl/DBs2pA+Sj340hcKkSdDc/N4BwVq1dSv84Afwta+lAc3rroMLLujfH27Ll8PPfgYzZ6axIkjjROeem74BDx26/Yd2LbeCe9uWLamVNns23H47/P736Xc6eXIKjTPO6PqE0B5yUFSL9ethr73gyivTrZq89lrqTrrnnvTz1VdT+RFHbGsxnHBCOr569sILqfvpwQfTh+2MGalrpL947bX0YTVrVvrgAjjmmBQO55zjWVx9YevWNKFj9uz0pfGVV9KXrJNOSlNuzzyzV861clBUk8bGdM2h2bPzrknn3n47fdgVu5OKlx/Zb780o6PYavAA7ntt3Qrf+x5ccUXqSvnud+H88/NrXaxalb7FzpyZzk3ZujWtvDhtWgqHxvcsKml9JSKdRFoMjRdeSC23iRNTaPzpn6Zp9RXgoKgmZ52VuqC+9a00yNXZrS/nZG/dmvqmi91Jv/1tGnsYPDhdDqPYahg/3l0Q5Vq8OLUuHnoozYD593+v2B99l958Mw2mzpqV/j3b2lIgTJuWWg9H1t7y9FUvIv0N3nZbWppg0aL05eLjH0+hcdZZPfpi5qCoJtddl64fVI5Bg7oOkz32SLMoytmu9DZ4cLpkQbHFcO+96fIikC43MmlSCofjj8//RLdqtmUL/Nu/wde/nqZIfu978Gd/1juti3Xr0hVwZ81Kc/w3bUpdScVwGD++f4+Z2DYRsHBhCo3iZfAB/vEf4aqrduolHRTVJCL1E69bl8YsKnXbsKF79RgwYNv0xAMO2NaVdPLJffett54sWpSuTPvoo6kP+oYb4H3v6/nrbtiQQmHmzHTi14YNaUzknHNSQEyY4HCoBc8/n0Lj2GPT3+hOcFBY6jp6++3uhcvw4SkcjjrKHyZ9YcuWdK7FN76RWoHf/376pt/d3/2mTakVOGtW6l5aty4Nfn7mM+n1Pv5xdw/aezgozKrJs8+m1sVjj6W+5x/8IF3epTNtbems9pkz05z8NWvSdMqzzkoth4kTq+bidJaPii6FKmmKpEWSlki6fAfbnCNpoaQFkn5aUn6NpPnZ7dyS8jGSfpe95ixJg7PyIdnjJdnzo8upo1lV+8AH0gD31VenMYUjj0znM7S3dWs6R+ULX0jdSZMnp0HO009P3UyvvZYuTHjyyQ4Jq5yI6PQGDABeAA4FBgNPAePabdMIPAEMyx7vn/08DZhDWvdiD2AusHf23M+Aadn9G4C/ze5/Abghuz8NmNVVHY855pgwqxnz50c0N0dAxGc+E/GHP0Q88kjEl78ccdBBqXy33SLOOSfi9tsjNmzIu8ZWpYDW6OLzNSLKalFMAJZExNKI2ATMBKa22+ZC4PqIWJOFz+tZ+TjggYhoi4j1wNPAFEkCTgSKJw7cApyZ3Z+aPSZ7/qRse7P6cOSRaSnXq65K4w0HHZTOjv7hD9NA9K23pks/zJqV5tRX04UTrSqVExQjgGUlj5dnZaXGAmMlPSTpUUlTsvKnSMGwu6T9gE8Co4DhwBsR0dbBa777ftnzb2bbm9WPgQPTtMfHH0/Lrd5ySwqHn/88jT/kdBE5q0+V6sQcSOp+mgiMBB6QVIiIeyQdCzwMrAQeAbqPY5PVAAADuUlEQVRxecgdk3QRcBHAwQcfXImXNOt/jjoqzYQyy1E5LYoVpFZA0cisrNRyoCUiNkfEi8DzpOAgIq6KiPERMQlQ9twqYKikgR285rvvlz2/T7b9diJiRkQ0R0Rzg9ebNjPrNeUExVygMZulNJg0wNzSbps7SK0Jsi6mscBSSQMkDc/Km4Am4J5sEOXXwNnZ/hcA/53db8kekz1/X7a9mZnloMuup4hok3QxcDdpBtTNEbFA0nTSiHlL9txkSQtJXUtfiYhVknYFHszGotcC55eMS3wNmCnpn0kzpoprgd4E/KekJcBqUjCZmVlOfMKdmVmdqugJd2ZmVr8cFGZm1ikHhZmZdcpBYWZmnaqJwWxJK4GXd3L3/YA/VrA61c6/j+3597GNfxfbq4XfxyER0eWJaDURFD0hqbWcUf964d/H9vz72Ma/i+3V0+/DXU9mZtYpB4WZmXXKQQEz8q5AP+Pfx/b8+9jGv4vt1c3vo+7HKMzMrHNuUZiZWafqOijKWQu8XkgaJenXJeuefznvOuUtu/rxE5J+mXdd8iZpqKTZkp6T9Kyk4/KuU14kXZb9jcyXdGt28dOaVrdBIWkAcD1wKmnJ1vMkjcu3VrlqA/4+IsYBHwG+WOe/D4AvA8/mXYl+4t+A/4mII4APUqe/F0kjgEuA5og4inRF7Zq/wnXdBgXlrQVeNyLi1Yh4PLv/FumDoP2St3VD0kjgNODGvOuSN0n7AJ8gWwogIjZFxBv51ipXA4HdsoXVdgd+n3N9el09B0U5a4HXJUmjgQ8Bv8u3Jrm6DvgqsDXvivQDY0hLGf8464q7UdIeeVcqDxGxAvgO8ArwKvBmRNyTb616Xz0HhXVA0p7AbcClEbE27/rkQdLpwOsRMS/vuvQTA4GjgR9GxIeA9UBdjulJGkbqeRgDHATsIen8fGvV++o5KMpZC7yuSBpEComfRMTtedcnRx8DzpD0EqlL8kRJ/y/fKuVqObA8IootzNmk4KhHJwMvRsTKiNgM3A58NOc69bp6Dopy1gKvG0rr1d4EPBsR/5p3ffIUEVdExMiIGE36f3FfRNT8t8YdiYjXgGWSDs+KTgIW5lilPL0CfETS7tnfzEnUwcB+l2tm16odrQWec7Xy9DHgL4BnJD2Zlf1jRNyZY52s//gS8JPsS9VS4HM51ycXEfE7SbOBx0kzBZ+gDs7Q9pnZZmbWqXruejIzszI4KMzMrFMOCjMz65SDwszMOuWgMDOzTjkozMysUw4KMzPrlIPCzMw69f8B4Dcl0ikuyA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### How did you preprocess this dataset ?\n",
    "\n",
    "\n",
    "### Which classifier reaches the highest classification accuracy in this dataset ?\n",
    "\n",
    "\n",
    "#### Why ?\n",
    "\n",
    "\n",
    "#### Can this result remain if the dataset is different ?\n",
    "\n",
    "\n",
    "### How did you improve your classifiers ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
