{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FDA_hw3\n",
    "\n",
    "## Logistic Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model, metrics, model_selection\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2009</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2009</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2009</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-2009</td>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12-Jan-2009</td>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13-Jan-2009</td>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14-Jan-2009</td>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-Jan-2009</td>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume\n",
       "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080\n",
       "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016\n",
       "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032\n",
       "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032\n",
       "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952\n",
       "5  09-Jan-2009      909.91       890.35      911.93     888.31  4716499968\n",
       "6  12-Jan-2009      890.40       870.26      890.40     864.32  4725049856\n",
       "7  13-Jan-2009      869.79       871.79      877.02     862.02  5017469952\n",
       "8  14-Jan-2009      867.28       842.62      867.28     836.93  5407880192\n",
       "9  15-Jan-2009      841.99       843.74      851.59     817.04  7807350272"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('training.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Close Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2018</td>\n",
       "      <td>2683.73</td>\n",
       "      <td>2695.81</td>\n",
       "      <td>2695.89</td>\n",
       "      <td>2682.36</td>\n",
       "      <td>1846463232</td>\n",
       "      <td>2713.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>03-Jan-2018</td>\n",
       "      <td>2697.85</td>\n",
       "      <td>2713.06</td>\n",
       "      <td>2714.37</td>\n",
       "      <td>2697.77</td>\n",
       "      <td>2090595328</td>\n",
       "      <td>2723.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04-Jan-2018</td>\n",
       "      <td>2719.31</td>\n",
       "      <td>2723.99</td>\n",
       "      <td>2729.29</td>\n",
       "      <td>2719.07</td>\n",
       "      <td>2100767744</td>\n",
       "      <td>2743.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>05-Jan-2018</td>\n",
       "      <td>2731.33</td>\n",
       "      <td>2743.15</td>\n",
       "      <td>2743.45</td>\n",
       "      <td>2727.92</td>\n",
       "      <td>1918869120</td>\n",
       "      <td>2747.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2018</td>\n",
       "      <td>2742.67</td>\n",
       "      <td>2747.71</td>\n",
       "      <td>2748.51</td>\n",
       "      <td>2737.60</td>\n",
       "      <td>1894823936</td>\n",
       "      <td>2751.29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0  02-Jan-2018     2683.73      2695.81     2695.89    2682.36  1846463232   \n",
       "1  03-Jan-2018     2697.85      2713.06     2714.37    2697.77  2090595328   \n",
       "2  04-Jan-2018     2719.31      2723.99     2729.29    2719.07  2100767744   \n",
       "3  05-Jan-2018     2731.33      2743.15     2743.45    2727.92  1918869120   \n",
       "4  08-Jan-2018     2742.67      2747.71     2748.51    2737.60  1894823936   \n",
       "\n",
       "   Tomorrow Close Price  \n",
       "0               2713.06  \n",
       "1               2723.99  \n",
       "2               2743.15  \n",
       "3               2747.71  \n",
       "4               2751.29  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['Tomorrow Close Price'] = train['Close Price'].shift(-1)\n",
    "test['Tomorrow Close Price'] = test['Close Price'].shift(-1)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Close Price</th>\n",
       "      <th>Tomorrow Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02-Jan-2009</td>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "      <td>927.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>05-Jan-2009</td>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>934.70</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>06-Jan-2009</td>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>906.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>07-Jan-2009</td>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>909.73</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>08-Jan-2009</td>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>890.35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>09-Jan-2009</td>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "      <td>870.26</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>12-Jan-2009</td>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "      <td>871.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13-Jan-2009</td>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "      <td>842.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>14-Jan-2009</td>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "      <td>843.74</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15-Jan-2009</td>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "      <td>850.12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date  Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0  02-Jan-2009      902.99       931.80      934.73     899.35  4048270080   \n",
       "1  05-Jan-2009      929.17       927.45      936.63     919.53  5413910016   \n",
       "2  06-Jan-2009      931.17       934.70      943.85     927.28  5392620032   \n",
       "3  07-Jan-2009      927.45       906.65      927.45     902.37  4704940032   \n",
       "4  08-Jan-2009      905.73       909.73      910.00     896.81  4991549952   \n",
       "5  09-Jan-2009      909.91       890.35      911.93     888.31  4716499968   \n",
       "6  12-Jan-2009      890.40       870.26      890.40     864.32  4725049856   \n",
       "7  13-Jan-2009      869.79       871.79      877.02     862.02  5017469952   \n",
       "8  14-Jan-2009      867.28       842.62      867.28     836.93  5407880192   \n",
       "9  15-Jan-2009      841.99       843.74      851.59     817.04  7807350272   \n",
       "\n",
       "   Tomorrow Close Price  Tomorrow Increase  \n",
       "0                927.45                  0  \n",
       "1                934.70                  1  \n",
       "2                906.65                  0  \n",
       "3                909.73                  1  \n",
       "4                890.35                  0  \n",
       "5                870.26                  0  \n",
       "6                871.79                  1  \n",
       "7                842.62                  0  \n",
       "8                843.74                  1  \n",
       "9                850.12                  1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    if x[1] > x[0]:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "train['Tomorrow Increase'] = train[['Close Price', 'Tomorrow Close Price']].apply(f, axis=1)\n",
    "test['Tomorrow Increase'] = test[['Close Price', 'Tomorrow Close Price']].apply(f, axis=1)\n",
    "train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Tomorrow Increase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price      Volume  \\\n",
       "0      902.99       931.80      934.73     899.35  4048270080   \n",
       "1      929.17       927.45      936.63     919.53  5413910016   \n",
       "2      931.17       934.70      943.85     927.28  5392620032   \n",
       "3      927.45       906.65      927.45     902.37  4704940032   \n",
       "4      905.73       909.73      910.00     896.81  4991549952   \n",
       "\n",
       "   Tomorrow Increase  \n",
       "0                  0  \n",
       "1                  1  \n",
       "2                  0  \n",
       "3                  1  \n",
       "4                  0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = train.drop(['Date', 'Tomorrow Close Price'], axis=1)\n",
    "test = test.drop(['Date', 'Tomorrow Close Price'], axis=1)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open Price</th>\n",
       "      <th>Close Price</th>\n",
       "      <th>High Price</th>\n",
       "      <th>Low Price</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>902.99</td>\n",
       "      <td>931.80</td>\n",
       "      <td>934.73</td>\n",
       "      <td>899.35</td>\n",
       "      <td>4048270080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>929.17</td>\n",
       "      <td>927.45</td>\n",
       "      <td>936.63</td>\n",
       "      <td>919.53</td>\n",
       "      <td>5413910016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>931.17</td>\n",
       "      <td>934.70</td>\n",
       "      <td>943.85</td>\n",
       "      <td>927.28</td>\n",
       "      <td>5392620032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>927.45</td>\n",
       "      <td>906.65</td>\n",
       "      <td>927.45</td>\n",
       "      <td>902.37</td>\n",
       "      <td>4704940032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>905.73</td>\n",
       "      <td>909.73</td>\n",
       "      <td>910.00</td>\n",
       "      <td>896.81</td>\n",
       "      <td>4991549952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>909.91</td>\n",
       "      <td>890.35</td>\n",
       "      <td>911.93</td>\n",
       "      <td>888.31</td>\n",
       "      <td>4716499968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>890.40</td>\n",
       "      <td>870.26</td>\n",
       "      <td>890.40</td>\n",
       "      <td>864.32</td>\n",
       "      <td>4725049856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>869.79</td>\n",
       "      <td>871.79</td>\n",
       "      <td>877.02</td>\n",
       "      <td>862.02</td>\n",
       "      <td>5017469952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>867.28</td>\n",
       "      <td>842.62</td>\n",
       "      <td>867.28</td>\n",
       "      <td>836.93</td>\n",
       "      <td>5407880192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>841.99</td>\n",
       "      <td>843.74</td>\n",
       "      <td>851.59</td>\n",
       "      <td>817.04</td>\n",
       "      <td>7807350272</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Open Price  Close Price  High Price  Low Price      Volume\n",
       "0      902.99       931.80      934.73     899.35  4048270080\n",
       "1      929.17       927.45      936.63     919.53  5413910016\n",
       "2      931.17       934.70      943.85     927.28  5392620032\n",
       "3      927.45       906.65      927.45     902.37  4704940032\n",
       "4      905.73       909.73      910.00     896.81  4991549952\n",
       "5      909.91       890.35      911.93     888.31  4716499968\n",
       "6      890.40       870.26      890.40     864.32  4725049856\n",
       "7      869.79       871.79      877.02     862.02  5017469952\n",
       "8      867.28       842.62      867.28     836.93  5407880192\n",
       "9      841.99       843.74      851.59     817.04  7807350272"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'Tomorrow Increase'\n",
    "x_train = train.loc[:, train.columns != col]\n",
    "y_train = train[col]\n",
    "x_test = test.loc[:, test.columns != col]\n",
    "y_test = test[col]\n",
    "x_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, x_train, y_train, x_test, y_test):\n",
    "    train_preds = model.predict(x_train)\n",
    "    test_preds = model.predict(x_test)\n",
    "    train_acc = metrics.accuracy_score(y_train, train_preds)\n",
    "    test_acc = metrics.accuracy_score(y_test, test_preds)\n",
    "    print('Train accuracy: %s' % train_acc)\n",
    "    print('Test accuracy: %s' % test_acc)\n",
    "    print(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py:183: FutureWarning: max_iter and tol parameters have been added in SGDClassifier in 0.19. If max_iter is set but tol is left unset, the default value for tol in 0.19 and 0.20 will be None (which is equivalent to -infinity, so it has no effect) but will change in 0.21 to 1e-3. Specify tol to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.4540636042402827\n",
      "Test accuracy: 0.4801587301587302\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "model_bl = linear_model.SGDClassifier(loss='log', max_iter=10000)\n",
    "model_bl.fit(x_train, y_train)\n",
    "evaluate(model_bl, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.5459363957597173\n",
      "Test accuracy: 0.5198412698412699\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = LogisticRegression().fit(x_train, y_train)\n",
    "evaluate(clf, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/preprocessing/data.py:645: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:6: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  \n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by StandardScaler.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.11792884,  2.14183026,  2.1280369 ,  2.13182543, -0.81568088],\n",
       "       [ 2.14703114,  2.17738855,  2.16616345,  2.16356794, -0.6350265 ],\n",
       "       [ 2.19126169,  2.1999191 ,  2.19694528,  2.20744305, -0.62749905],\n",
       "       ...,\n",
       "       [ 1.62073705,  1.71517201,  1.7014033 ,  1.54595882, -0.41608606],\n",
       "       [ 1.73671343,  1.70880244,  1.76571091,  1.70034565, -0.64232918],\n",
       "       [ 1.73706381,  1.75231754,  1.74295464,  1.7208001 , -0.76668134]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "\n",
    "x_train_std = scaler.transform(x_train)\n",
    "x_test_std = scaler.transform(x_test)\n",
    "x_test_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Custom kernel function\\ndef my_kernel(X, Y):\\n    return np.dot(X, Y.T)\\n  \\npenalty = 0.05\\n\\nsvm = SVC(C=penalty, kernel=\"linear\", probability=True)\\nsvm.fit(x_train, y_train)\\n  \\nacc_rate = accuracy_score(y_test, svm.predict(x_test)) * 100\\nprint(\"Penalty = %.2f, Accuracy = %.2f %%\" % (penalty, acc_rate))\\n'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "'''\n",
    "# Custom kernel function\n",
    "def my_kernel(X, Y):\n",
    "    return np.dot(X, Y.T)\n",
    "  \n",
    "penalty = 0.05\n",
    "\n",
    "svm = SVC(C=penalty, kernel=\"linear\", probability=True)\n",
    "svm.fit(x_train, y_train)\n",
    "  \n",
    "acc_rate = accuracy_score(y_test, svm.predict(x_test)) * 100\n",
    "print(\"Penalty = %.2f, Accuracy = %.2f %%\" % (penalty, acc_rate))\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers, regularizers\n",
    "import random\n",
    "from sklearn import preprocessing\n",
    "import tensorflow as tf\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    1236\n",
       "0    1028\n",
       "Name: Tomorrow Increase, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    131\n",
       "0    121\n",
       "Name: Tomorrow Increase, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dimension = 5\n",
    "hidden_units = 10    # how many neurons in the hidden layer\n",
    "activation = 'relu'  # activation function for hidden layer\n",
    "l2 = 0.001           # regularization - how much we penalize large parameter values\n",
    "learning_rate = 0.1  # how big our steps are in gradient descent\n",
    "epochs = 20          # how many epochs to train for\n",
    "batch_size = 32      # how many samples to use for each gradient descent update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# create a sequential model\n",
    "model = models.Sequential()\n",
    "# add the hidden layer\n",
    "model.add(layers.Dense(input_dim=input_dimension,\n",
    "                       units=hidden_units, \n",
    "                       activation=activation))\n",
    "# add the output layer\n",
    "model.add(layers.Dense(input_dim=hidden_units,\n",
    "                       units=1,\n",
    "                       activation='sigmoid'))\n",
    "# define our loss function and optimizer\n",
    "# Adam is a kind of gradient descent\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=learning_rate),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/10\n",
      "2264/2264 [==============================] - 0s 166us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 2/10\n",
      "2264/2264 [==============================] - 0s 45us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 3/10\n",
      "2264/2264 [==============================] - 0s 45us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 4/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 5/10\n",
      "2264/2264 [==============================] - 0s 45us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 6/10\n",
      "2264/2264 [==============================] - 0s 50us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 7/10\n",
      "2264/2264 [==============================] - 0s 48us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 8/10\n",
      "2264/2264 [==============================] - 0s 44us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 9/10\n",
      "2264/2264 [==============================] - 0s 44us/step - loss: 8.7995 - acc: 0.4541\n",
      "Epoch 10/10\n",
      "2264/2264 [==============================] - 0s 44us/step - loss: 8.7995 - acc: 0.4541\n",
      "2264/2264 [==============================] - 0s 31us/step\n",
      "252/252 [==============================] - 0s 44us/step\n",
      "Training accuracy: 0.4540636044508998\n",
      "Testing accuracy: 0.4801587329970466\n"
     ]
    }
   ],
   "source": [
    "# train the parameters\n",
    "history = model.fit(x_train, y_train, epochs=10, batch_size=batch_size)\n",
    "\n",
    "# evaluate accuracy\n",
    "train_acc = model.evaluate(x_train, y_train, batch_size=32)[1]\n",
    "test_acc = model.evaluate(x_test, y_test, batch_size=32)[1]\n",
    "print('Training accuracy: %s' % train_acc)\n",
    "print('Testing accuracy: %s' % test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.],\n",
       "       [0.]], dtype=float32)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = history.history['loss']\n",
    "plt.plot(range(len(losses)), losses, 'r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "\n",
    "### How did you preprocess this dataset ?\n",
    "\n",
    "\n",
    "### Which classifier reaches the highest classification accuracy in this dataset ?\n",
    "\n",
    "\n",
    "#### Why ?\n",
    "\n",
    "\n",
    "#### Can this result remain if the dataset is different ?\n",
    "\n",
    "\n",
    "### How did you improve your classifiers ?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
